\documentclass[twocolumn]{article}

% Recommended, but optional, pac  \end{tabular}}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}
% Ensure floats (figures) don't pass certain points
\usepackage{placeins}

% Safer inclusion of paths that contain spaces/underscores
\newcommand{\img}[2][]{\includegraphics[#1]{\detokenize{#2}}}

\begin{document}

\title{Task 2: Generative Models --- VAEs vs GANs}
\author{ATML Assignment 1}
\maketitle

\section{Introduction}
In this section we will focus on how inductive biases in model purpose or architecture shape how the generative models learn, capture and represent data. The generative models we will discuss are Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs). VAEs optimize an ELBO loss (reconstruction + KL loss) making a structured latent space with smooth interpolations helping in generating reconstructions despite being blurry and lacking detail. GANs on the other hand use adversarial training, where generator tries to generate an output that the discriminator cannot classify as real or fake. This helps GANs produce sharp, realistic samples, however in GANs thereâ€™s no encoder to structure the latent space making the generations unreliable to some extent. 

We will evaluate VAEs and GANs trained on MNIST (28\,\texttimes\,28), CIFAR-10 (32\,\texttimes\,32), and CelebA (64\,\texttimes\,64). Our analysis will include (i) reconstruction quality and how it reflects latent organization. (ii) realism vs diversity tradeoff, (iii) latent-space interpolations and semantnic structure, and (iv) model behavior on OOD inputs.

\section{Datasets and Preprocessing}
\textbf{MNIST} (28\,\texttimes\,28 grayscale): Normalized to $[-1,1]$ with mean=0.5, std=0.5; batch size 128.\\
\textbf{CIFAR-10} (32\,\texttimes\,32 RGB): Normalized channel-wise to $[-1,1]$ with mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5); batch size 128.\\
\textbf{CelebA} (178\,\texttimes\,218 RGB): CenterCrop(178) then resized to 64\,\texttimes\,64 (no normalization); batch size 128.

\section{Models and Training Setup}

\begin{table}[h]
  \centering
  \large\bfseries
  \renewcommand{\arraystretch}{1.5}
  \resizebox{\linewidth}{!}{%
  \begin{tabular}{l l l}
    \toprule
    Model & Optimizer (lr, betas) & Loss \\
    \midrule
    VAE CIFAR-10 & Adam (1e-3) & MSE + KL \\
    VAE MNIST & Adam (1e-3) & MSE + KL \\
    VAE CelebA & Adam (1e-3) & BCE + KL (decoder Sigmoid) \\
    DCGAN CIFAR-10 & Adam (2e-4, 0.5, 0.999) & BCE-with-logits \\
    DCGAN MNIST & Adam (G:2e-3, D:1e-3) & BCE-with-logits \\
    DCGAN CelebA & -- & BCE-with-logits \\
    \bottomrule
  \end{tabular}}
  \normalfont
  \caption{Key hyperparameters and training settings for VAEs and DCGANs.}
  \label{tab:models}
\end{table}

All models use \textbf{batch size 128}. \textbf{Latent dimensions}: VAE CIFAR-10/MNIST: 64, VAE CelebA: 200, DCGAN all: 64. \textbf{Epochs}: VAE CIFAR-10/DCGAN CIFAR-10: 150, VAE MNIST/DCGAN MNIST: 30, VAE CelebA: 20, DCGAN CelebA: pretrained.


\section{Results}
We organize results by dataset with paired VAE/GAN visuals. All images referenced below are generated by the corresponding notebooks in the repository.

\subsection{Visual Quality vs Diversity} \

GAN samples are sharper images with finer details than VAE. The adversarial loss pushes for realism so textures become more defined as we go through
epochs. Also since it was a well pretrained GAN, the mode collapse is avoided and decent diversity is observed, however, as the training samples contained more images of woman, the model becomes slighly biased towards generating images of woman.
VAE on the other hand was trained in house, the visuals are smoothed due to the KL term leading to blurry samples.
Also since the gender ratio of CelebA is unbalanced towards woman, the model tends to generate more features related to woman. 


\begin{figure}[h]
\centering
\subfigure[VAE Generated Samples\label{fig:celeba_samples_vae}]{\img[width=\columnwidth]{things to add/Samples_CelebA_VAE.png}}\\
\subfigure[GAN Generated Samples\label{fig:celeba_samples_gan}]{\img[width=\columnwidth]{things to add/Samples_CelebA_GAN.png}}
\caption{Comparison of generated samples from VAE and GAN on CelebA dataset.}
\label{fig:celeba_samples}
\end{figure}
% \FloatBarrier

\begin{table}[h]
  \centering
  \small
  \resizebox{\columnwidth}{!}{%
  \begin{tabular}{lcccc}
    Model & MSE & SSIM & FID & KID \\
    \midrule
    GAN (CelebA) & - & - & 97.1 & 0.015 \\
    VAE (CelebA) & 0.010 & 0.677 & 136.0 & 0.088 \\
    \bottomrule
  \end{tabular}}
  \caption{CelebA metrics}
  \label{tab:celeba_metrics}
\end{table}
\FloatBarrier

VAE acheived better reconstrucion performance with lower (MSE = 0.010, SSIM = 0.677) showing that generations are related to input even if blurry, but poor sample quality with higher (FID = 136, KID = 0.088) meaning less realistic samples, despite fine reconstruction. This is because of the bias to cover all modes in data distribution at cost of fidelity.
In comparison GAN producing sharper, realistic samples that are closer to data distribution have a lower FID and KID (FID = 97.1, KID = 0.015) consistent with adversarial training bias toward perceptual realism.

\FloatBarrier

\subsection{Latent Space Analysis}

The VAE MNIST interpolation results of latent space shows a smooth transition from 0 to 2. We can see that the interpolation passes through the digit 8. 
This also ties with the t-SNE analysis where cluster of 8 (mustard) is in between cluster of 0 (blue) and cluster of 2 (green). This shows that the latent space in VAE is continuous and semantically structured. 
In contrast, GAN interpolation from 7 to 9 is also smooth with sharp visuals and no discontinuity. GAN interpolation gives higher fidelity samples and avoid the morphing effect (low intensity pixels) as the generator is trained needs to fool the discriminator, 
the generator generates similar samples from a given input point and around that point as it has learned to fool the discriminator (slight mode bias), when it is given input from a specific subspace of latent space. VAE on the other hand produces lower intensity pixels and shows 
morphing effect as the latent space is pushed towards being continuous by the KL term. Lower intensity pixels in VAE are shown while traveling through (between) clusters. 
In the CelebA dataset, the VAE again produces smooth yet blurry interpolation, however in GAN there is irregularity might be due to discontinuity in latent space, though it generates much sharper images due to adversarial loss.


\FloatBarrier



\begin{figure}[h]
\centering
\subfigure[MNIST VAE interpolations\label{fig:mnist_interp_vae}]{\img[width=\columnwidth]{things to add/Interpolation_MNIST_VAE_2.png}}\\
\subfigure[MNIST GAN interpolations\label{fig:mnist_interp_gan}]{\img[width=\columnwidth]{things to add/Interpolation_MNIST_GAN_2.png}}\\
\subfigure[CelebA VAE interpolations\label{fig:celeba_interp_vae}]{\img[width=\columnwidth]{things to add/Interpolation_Celeba_VAE.png}}
\subfigure[CelebA GAN interpolations\label{fig:celeba_interp_gan}]{\img[width=\columnwidth]{things to add/Interpolation_Celeba_GAN_3.png}}
\caption{Latent space interpolations for MNIST and CelebA (VAE and GAN).}
\label{fig:interpolations}
\end{figure}

\FloatBarrier

MNIST plot of t-SNE show distinct cluster of number representations in latent space where clusters like 1 and 7 lie closer to each other due to similarity in how they 
are written, and clusters for 0 and 1 appear far from each other as they are dissimilar in writing, meaning that the latent space is continuous and semantically structured. The t-SNE for VAE latent trained on CelebA show the woman distributed on the entire normal while the men mainly clustered around a point. 
This means that model encoded greater variability in female faces (consistent with the dataset bias of gender ratio), while it learned less variability in men features as model saw fewer examples of men. 

\begin{figure}[h]
\centering
\subfigure[MNIST VAE t-SNE\label{fig:mnist_tsne_vae}]{\img[width=0.48\columnwidth]{things to add/TSNE_VAE_MNIST.png}}
\subfigure[CelebA VAE t-SNE\label{fig:celeba_tsne_vae}]{\img[width=0.48\columnwidth]{things to add/TSNE_CelebA_VAE.png}}
\caption{MNIST VAE latent space}
\label{fig:vae_latent_visualization_celeba}
\end{figure}


\begin{figure}[h]
\centering
\subfigure[Latent dimension sweep with auto-dim selection and flexible anchor \label{fig:mnist_tsne_vae}]{\img[width=\columnwidth]{things to add/Latent_Traversal_CelebA_VAE.png}}
\caption{Latent traversal on less important dimensions}
\label{fig:vae_latent_visualization_celeba}
\end{figure}


The figure above shows latent sweep while keeping the most responsive dimension constant. 
We can observe that the background and hair colour change as we traverse while the important dimension of facial features are the same. 
This signifies good learning across different dimensions as model learned important features and less important features distinctly. An important insight is the travsal 
varies the skin colour which indicates that features such as eyes, nose, face size and rest of facial features are represented distintly in latent space than skin colour of the person.


\subsection{OOD Robustness Analysis}

We tested OOD robustness of the VAE trained on MNIST by reconstructing hand written images through the model. 
VAE reconstructed good reconstructions with surprisingly less average reconstrucion error (23.35) than IID test data (30.36). 
The reason for this can be that the digits are really well written and the VAE is well trained and latent space is semantically organized well as can be seen 
by the t-SNE. The OOD inputs might have landed close to regions from where decoder produce plausible samples.  
Also the reconstrucion loss for simple digits (like 1 with a single stroke) 
is much lesser and reconstructions are better than more complex digits like 2 or 8. The blur on the OOD reconstrucions is higher as VAE's KL-regularized decoder tends to average inputs toward a smooth latent representation. 

In case of GAN, we tested the model on high variance N(0, 10) and shifted N(5, 1) inputs. The outputs for 
high variance are somewhat facelike but very distorted, indicating that the generator struggles with latent magnitude far beyond N(0, 1). 
For the shifted inputs the generator produces pure noise, without any meaning indicating that the generator cannot generalize on out of trained latent region. 
This means that GAN are not robust to extrapolation as generator is tightly bound to the standard normal. This tells about the bias toward high fidelity constructions 
within the training bounds but poor generalization specially outside the training support.

We also tested OOD robustness of the VAE trained on CelebA dataset by providing real world images. 
The VAE produced outputs with blurred background and edges, and average facelike structure unlike the real image with high average reconstrucion loss (209.2) indicating anomally detection. Five images of a man were given as input where four were 
distinct poses and one was a cropped version. Though all input images were of the same man, VAE reconstructed four out of 5 female faces and just one male face. Moreover every 
reconstructed face was different from other indicating reconstructions did not preserve identity and tended to 'hallucinate' plausible but mismatched samples rather than faithfully 
reproducing the true input. This reflects two inductive biases: i) the KL prior pushes reconstructions towards dominant regions of latent space, ii) the CelebA dataset unbalanced gender 
ratio biases the model to generate female-like ouputs. As a result, the VAE generalizes poorly to real-world OOD inputs and exhibits mode averaging rather than identity preservation.

\begin{figure}[h]
\centering
\subfigure[MNIST VAE OOD inputs\label{fig:mnist_ood_vae}]{\img[width=\columnwidth]{things to add/OOD_Input_MNIST_VAE_2.png}}\\
\subfigure[MNIST GAN OOD outputs\label{fig:mnist_ood_gan}]{\img[width=\columnwidth]{things to add/OOD_MNIST_GAN.png}}
\caption{OOD robustness on MNIST: VAE (up) and GAN (down)}
\label{fig:ood_mnist}
\end{figure}

\FloatBarrier


\begin{figure}[h]
\centering
\subfigure[CelebA VAE OOD inputs\label{fig:mnist_tsne_vae}]{\img[width=\columnwidth]{things to add/Recons_CelebA_VAE.png}}
\caption{CelebA VAE OOD Results}
\label{fig:vae_latent_visualization_celeba}
\end{figure}

\section{Training and Stability}

The VAE training on MNIST dataset was relatively smoother, than the training on CelebA dataset or training of GAN. First few epochs tuned KL-weight while loss reduced steadily. 
VAE trained on CelebA produced many challenges due to unbalanced gender ratio of dataset, training had to be just sufficient that model learns important features while not biasing 
toward generating only female faces. The training was run for reduced epochs (20) and monitored to get the best result. The KL-weight had o be kept optimal as high KL-weight produced 
overly blurred outputs and low KL-weight made the latent space collapse, and interpolations losing smoothness.

GANs being more delicate were harder to train due to mode collapse. When we were training GAN on CIFAR-10, the discriminator loss falling to zero indicating mode collapse while training 
was avoided later by decreasing learning rate. The adversarial setup led to oscillating generator and discriminator losses, and tuning was required to avoid either player overpowering the other. 
This reflects the inductive bias vs. flexibility trade-off: GANs achieve sharper, more realistic samples by focusing on distributional matching rather than explicit density estimation, but this makes 
training more unstable and prone to collapse compared to VAEs. This reflects the inductive bias vs. flexibility trade-off: GANs achieve sharper, more realistic samples by focusing on distributional matching 
rather than explicit density estimation, but this makes training more unstable and prone to collapse compared to VAEs.

\section{Conclusion}

In conclusion, our experiments on these generative models highlight distinct inductive biases in VAEs and GANs. Where VAEs are easy to train and learn entire true distribution, they produce blurry outputs. 
GANs while producing sharper, high quality images suffer with mode collapse while training and can lack diversity. Together, these findings illustrate the central fidelity-diversity trade-off. Understanding these biases 
not only explains the practical strengths and weaknesses of each model, but also informs the design of future generative 
approaches that seek to combine stability, representation quality, and realism.

\end{document}
